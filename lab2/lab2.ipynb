{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа #2\n",
    "\n",
    "## Сбор данных для обучения\n",
    "\n",
    "Датасет был собран путём парсинга сайта https://www.anekdot.ru/. Взял все анекдоты за 2021 год и 2020 года, всего около 54,000 штук.\n",
    "Для парсинга использовал библиотку `BeautifulSoup4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "years = ['2020', '2021']\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11']\n",
    "days = ['01', '02', '03', '04', '05', '06', '07', '08', '09'] + [str(x) for x in range(10, 29)]\n",
    "base_url = 'https://www.anekdot.ru/release/anekdot/day/'\n",
    "\n",
    "jokes = []\n",
    "for (year, month, day) in product(years, months, days):\n",
    "    if day == '01':\n",
    "        print(f'{year}.{month}...')\n",
    "\n",
    "    url = base_url + year + '-' + month + '-' + day + '/'\n",
    "    page = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    search_result = soup.find_all('div', class_='topicbox')\n",
    "\n",
    "    for box in search_result:\n",
    "        text = box.findAll('div', class_='text')\n",
    "        if len(text):\n",
    "            jokes.append(text[0].get_text().replace('\\r', ' ').replace('\\xad', ' '))\n",
    "\n",
    "print(f'Number of jokes: {len(jokes)}')\n",
    "\n",
    "df = pd.DataFrame({'Jokes': jokes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Читаем данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54244, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jokes_df = pd.read_csv('jokes.csv')\n",
    "jokes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54244 entries, 0 to 54243\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Jokes   54244 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 423.9+ KB\n"
     ]
    }
   ],
   "source": [
    "jokes_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение длин анекдотов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist([len(joke) for joke in jokes_df.Jokes.values], bins=32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датасет на тренировочную и валидационную выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(0.8 * jokes_df.shape[0])\n",
    "x_train = jokes_df.Jokes.values[:n_train].tolist()\n",
    "x_val = jokes_df.Jokes.values[n_train:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43395, 10849)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели\n",
    "\n",
    "За основу возьмём модель от Сбера и дообучим её на анекдотах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = 'sberbank-ai/rugpt3small_based_on_gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenized_train = tokenizer(x_train, truncation=True, padding='max_length', max_length=42)\n",
    "tokenized_val = tokenizer(x_val, truncation=True, padding='max_length', max_length=42)\n",
    "\n",
    "tokenized_train['labels'] = tokenized_train['input_ids'].copy()\n",
    "tokenized_val['labels'] = tokenized_val['input_ids'].copy()\n",
    "\n",
    "tokenized_train = Dataset.from_dict(tokenized_train)\n",
    "tokenized_val = Dataset.from_dict(tokenized_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments('test_trainer')\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_train, eval_dataset=tokenized_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 43395\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16275\n",
      "  3%|▎         | 500/16275 [24:04<12:33:20,  2.87s/it]Saving model checkpoint to test_trainer\\checkpoint-500\n",
      "Configuration saved in test_trainer\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9801, 'learning_rate': 4.846390168970814e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-500\\pytorch_model.bin\n",
      "  6%|▌         | 1000/16275 [48:15<12:22:03,  2.91s/it]Saving model checkpoint to test_trainer\\checkpoint-1000\n",
      "Configuration saved in test_trainer\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8076, 'learning_rate': 4.692780337941628e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-1000\\pytorch_model.bin\n",
      "  9%|▉         | 1500/16275 [1:12:58<11:36:44,  2.83s/it]Saving model checkpoint to test_trainer\\checkpoint-1500\n",
      "Configuration saved in test_trainer\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7654, 'learning_rate': 4.539170506912442e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-1500\\pytorch_model.bin\n",
      " 12%|█▏        | 2000/16275 [1:42:45<11:17:19,  2.85s/it]Saving model checkpoint to test_trainer\\checkpoint-2000\n",
      "Configuration saved in test_trainer\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7695, 'learning_rate': 4.385560675883257e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-2000\\pytorch_model.bin\n",
      " 15%|█▌        | 2500/16275 [2:07:11<11:13:48,  2.93s/it]Saving model checkpoint to test_trainer\\checkpoint-2500\n",
      "Configuration saved in test_trainer\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7252, 'learning_rate': 4.231950844854071e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-2500\\pytorch_model.bin\n",
      " 18%|█▊        | 3000/16275 [2:31:30<10:30:12,  2.85s/it]Saving model checkpoint to test_trainer\\checkpoint-3000\n",
      "Configuration saved in test_trainer\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7362, 'learning_rate': 4.078341013824885e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-3000\\pytorch_model.bin\n",
      " 22%|██▏       | 3500/16275 [2:59:59<13:39:43,  3.85s/it]Saving model checkpoint to test_trainer\\checkpoint-3500\n",
      "Configuration saved in test_trainer\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.738, 'learning_rate': 3.924731182795699e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-3500\\pytorch_model.bin\n",
      " 25%|██▍       | 4000/16275 [3:33:11<13:32:20,  3.97s/it]Saving model checkpoint to test_trainer\\checkpoint-4000\n",
      "Configuration saved in test_trainer\\checkpoint-4000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7172, 'learning_rate': 3.7711213517665136e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-4000\\pytorch_model.bin\n",
      " 28%|██▊       | 4500/16275 [4:06:17<12:45:25,  3.90s/it]Saving model checkpoint to test_trainer\\checkpoint-4500\n",
      "Configuration saved in test_trainer\\checkpoint-4500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7143, 'learning_rate': 3.6175115207373276e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-4500\\pytorch_model.bin\n",
      " 31%|███       | 5000/16275 [4:39:29<12:40:11,  4.05s/it]Saving model checkpoint to test_trainer\\checkpoint-5000\n",
      "Configuration saved in test_trainer\\checkpoint-5000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6718, 'learning_rate': 3.4639016897081416e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-5000\\pytorch_model.bin\n",
      " 34%|███▍      | 5500/16275 [5:12:33<11:34:19,  3.87s/it]Saving model checkpoint to test_trainer\\checkpoint-5500\n",
      "Configuration saved in test_trainer\\checkpoint-5500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6504, 'learning_rate': 3.3102918586789556e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-5500\\pytorch_model.bin\n",
      " 37%|███▋      | 6000/16275 [5:36:15<9:16:01,  3.25s/it] Saving model checkpoint to test_trainer\\checkpoint-6000\n",
      "Configuration saved in test_trainer\\checkpoint-6000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3254, 'learning_rate': 3.15668202764977e-05, 'epoch': 1.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-6000\\pytorch_model.bin\n",
      " 40%|███▉      | 6500/16275 [6:07:23<10:46:24,  3.97s/it]Saving model checkpoint to test_trainer\\checkpoint-6500\n",
      "Configuration saved in test_trainer\\checkpoint-6500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3353, 'learning_rate': 3.003072196620584e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-6500\\pytorch_model.bin\n",
      " 43%|████▎     | 7000/16275 [6:39:52<10:02:56,  3.90s/it]Saving model checkpoint to test_trainer\\checkpoint-7000\n",
      "Configuration saved in test_trainer\\checkpoint-7000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3329, 'learning_rate': 2.8494623655913982e-05, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-7000\\pytorch_model.bin\n",
      " 46%|████▌     | 7500/16275 [7:13:09<9:38:45,  3.96s/it] Saving model checkpoint to test_trainer\\checkpoint-7500\n",
      "Configuration saved in test_trainer\\checkpoint-7500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3397, 'learning_rate': 2.6958525345622122e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-7500\\pytorch_model.bin\n",
      " 49%|████▉     | 8000/16275 [7:46:29<9:18:33,  4.05s/it] Saving model checkpoint to test_trainer\\checkpoint-8000\n",
      "Configuration saved in test_trainer\\checkpoint-8000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3369, 'learning_rate': 2.542242703533026e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-8000\\pytorch_model.bin\n",
      " 52%|█████▏    | 8500/16275 [8:19:41<8:40:08,  4.01s/it] Saving model checkpoint to test_trainer\\checkpoint-8500\n",
      "Configuration saved in test_trainer\\checkpoint-8500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3365, 'learning_rate': 2.3886328725038402e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-8500\\pytorch_model.bin\n",
      " 55%|█████▌    | 9000/16275 [8:52:56<7:58:23,  3.95s/it] Saving model checkpoint to test_trainer\\checkpoint-9000\n",
      "Configuration saved in test_trainer\\checkpoint-9000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3462, 'learning_rate': 2.2350230414746546e-05, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-9000\\pytorch_model.bin\n",
      " 58%|█████▊    | 9500/16275 [9:26:16<7:25:32,  3.95s/it] Saving model checkpoint to test_trainer\\checkpoint-9500\n",
      "Configuration saved in test_trainer\\checkpoint-9500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3677, 'learning_rate': 2.0814132104454685e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-9500\\pytorch_model.bin\n",
      " 61%|██████▏   | 10000/16275 [9:59:28<7:02:23,  4.04s/it]Saving model checkpoint to test_trainer\\checkpoint-10000\n",
      "Configuration saved in test_trainer\\checkpoint-10000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3453, 'learning_rate': 1.927803379416283e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-10000\\pytorch_model.bin\n",
      " 65%|██████▍   | 10500/16275 [10:32:47<6:21:33,  3.96s/it]Saving model checkpoint to test_trainer\\checkpoint-10500\n",
      "Configuration saved in test_trainer\\checkpoint-10500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.352, 'learning_rate': 1.774193548387097e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-10500\\pytorch_model.bin\n",
      " 68%|██████▊   | 11000/16275 [11:12:40<5:56:36,  4.06s/it]Saving model checkpoint to test_trainer\\checkpoint-11000\n",
      "Configuration saved in test_trainer\\checkpoint-11000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2726, 'learning_rate': 1.6205837173579112e-05, 'epoch': 2.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-11000\\pytorch_model.bin\n",
      " 71%|███████   | 11500/16275 [17:55:24<5:11:55,  3.92s/it]     Saving model checkpoint to test_trainer\\checkpoint-11500\n",
      "Configuration saved in test_trainer\\checkpoint-11500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0613, 'learning_rate': 1.4669738863287252e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-11500\\pytorch_model.bin\n",
      " 74%|███████▎  | 12000/16275 [18:28:22<4:35:43,  3.87s/it]Saving model checkpoint to test_trainer\\checkpoint-12000\n",
      "Configuration saved in test_trainer\\checkpoint-12000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0834, 'learning_rate': 1.313364055299539e-05, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-12000\\pytorch_model.bin\n",
      " 77%|███████▋  | 12500/16275 [19:01:12<4:08:10,  3.94s/it]Saving model checkpoint to test_trainer\\checkpoint-12500\n",
      "Configuration saved in test_trainer\\checkpoint-12500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0731, 'learning_rate': 1.1597542242703534e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-12500\\pytorch_model.bin\n",
      " 80%|███████▉  | 13000/16275 [19:34:12<3:29:12,  3.83s/it]Saving model checkpoint to test_trainer\\checkpoint-13000\n",
      "Configuration saved in test_trainer\\checkpoint-13000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0955, 'learning_rate': 1.0061443932411675e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-13000\\pytorch_model.bin\n",
      " 83%|████████▎ | 13500/16275 [20:07:18<3:04:36,  3.99s/it]Saving model checkpoint to test_trainer\\checkpoint-13500\n",
      "Configuration saved in test_trainer\\checkpoint-13500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1127, 'learning_rate': 8.525345622119817e-06, 'epoch': 2.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-13500\\pytorch_model.bin\n",
      " 86%|████████▌ | 14000/16275 [20:38:18<1:39:26,  2.62s/it]Saving model checkpoint to test_trainer\\checkpoint-14000\n",
      "Configuration saved in test_trainer\\checkpoint-14000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0953, 'learning_rate': 6.989247311827957e-06, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-14000\\pytorch_model.bin\n",
      " 89%|████████▉ | 14500/16275 [21:01:57<1:17:43,  2.63s/it]Saving model checkpoint to test_trainer\\checkpoint-14500\n",
      "Configuration saved in test_trainer\\checkpoint-14500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0894, 'learning_rate': 5.453149001536099e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-14500\\pytorch_model.bin\n",
      " 92%|█████████▏| 15000/16275 [21:26:08<55:54,  2.63s/it]  Saving model checkpoint to test_trainer\\checkpoint-15000\n",
      "Configuration saved in test_trainer\\checkpoint-15000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1133, 'learning_rate': 3.9170506912442395e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-15000\\pytorch_model.bin\n",
      " 95%|█████████▌| 15500/16275 [21:48:21<35:29,  2.75s/it]  Saving model checkpoint to test_trainer\\checkpoint-15500\n",
      "Configuration saved in test_trainer\\checkpoint-15500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.089, 'learning_rate': 2.3809523809523808e-06, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-15500\\pytorch_model.bin\n",
      " 98%|█████████▊| 16000/16275 [22:11:21<11:11,  2.44s/it]Saving model checkpoint to test_trainer\\checkpoint-16000\n",
      "Configuration saved in test_trainer\\checkpoint-16000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0904, 'learning_rate': 8.448540706605223e-07, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-16000\\pytorch_model.bin\n",
      "100%|██████████| 16275/16275 [22:23:19<00:00,  2.19s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 16275/16275 [22:23:19<00:00,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 80599.6391, 'train_samples_per_second': 1.615, 'train_steps_per_second': 0.202, 'train_loss': 2.3969583153321814, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16275, training_loss=2.3969583153321814, metrics={'train_runtime': 80599.6391, 'train_samples_per_second': 1.615, 'train_steps_per_second': 0.202, 'train_loss': 2.3969583153321814, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация анекдотов\n",
    "\n",
    "Вроде бы даже похожи на настоящие :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(prompt, max_length=100, top_p=0.95, top_k=60):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=max_length, do_sample=True, top_p=top_p, top_k=top_k)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Встретились американец, француз и русский в бане. Подходит русский:- У вас в Америке гей не принимает? Я вчера в одной стране гей принял!- Ну что, совсем гей?- Это не мой, а жена его пришла.ствовать.орова���удууду'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_joke('Встретились американец, француз и русский')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Вступительная лекция в техническом ВУЗе.  На лекции по физике в деканате.   Издается объявление: «Курс по компьютерной игре. Преподаватель. Имеющийся опыт работы в области компьютерных игр позволяет проводить занятия на удалёнке»'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_joke('Вступительная лекция в техническом ВУЗе. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Поручик Ржевский танцует с Наташей Ростовой: \"Я тебя люблю, как конь в стае\", но её уже не остановить..'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_joke('Поручик Ржевский танцует с Наташей Ростовой:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecce475e34837bcc412e1737deec36f692a1fa6e3739e0394b2e0a1aa463a7d6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
