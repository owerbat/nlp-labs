{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа #2\n",
    "\n",
    "## Сбор данных для обучения\n",
    "\n",
    "Датасет был собран путём парсинга сайта https://www.anekdot.ru/. Взял все анекдоты за 2021 год и 2020 года, всего около 54,000 штук.\n",
    "Для парсинга использовал библиотку `BeautifulSoup4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "years = ['2020', '2021']\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11']\n",
    "days = ['01', '02', '03', '04', '05', '06', '07', '08', '09'] + [str(x) for x in range(10, 29)]\n",
    "base_url = 'https://www.anekdot.ru/release/anekdot/day/'\n",
    "\n",
    "jokes = []\n",
    "for (year, month, day) in product(years, months, days):\n",
    "    if day == '01':\n",
    "        print(f'{year}.{month}...')\n",
    "\n",
    "    url = base_url + year + '-' + month + '-' + day + '/'\n",
    "    page = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    search_result = soup.find_all('div', class_='topicbox')\n",
    "\n",
    "    for box in search_result:\n",
    "        text = box.findAll('div', class_='text')\n",
    "        if len(text):\n",
    "            jokes.append(text[0].get_text().replace('\\r', ' ').replace('\\xad', ' '))\n",
    "\n",
    "print(f'Number of jokes: {len(jokes)}')\n",
    "\n",
    "df = pd.DataFrame({'Jokes': jokes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем полученный ранее датасет и оставляем первые 9000 анекдотов, чтобы данные влезали в память.\n",
    "\n",
    "Уверен, есть способ обучиться на всём датасете, но я его не нашёл :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df = pd.read_csv('jokes.csv')\n",
    "jokes = jokes_df.Jokes.values[:9000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём токенайзер, который будет переводить слова в числа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 50000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(jokes)\n",
    "sequences = tokenizer.texts_to_sequences(jokes)\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающая выборка представляет из себя наборы из 6 слов. По певым пяти пытаемся предсказать следующее слово из анекдота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_len = 6\n",
    "pred_len = 1\n",
    "train_len = sentence_len - pred_len\n",
    "seq = []\n",
    "\n",
    "for joke in sequences:\n",
    "    if len(joke) >= sentence_len:\n",
    "        for i in range(len(joke) - sentence_len):\n",
    "            seq.append(joke[i: i + sentence_len])\n",
    "\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "x_train = np.array([i[:train_len] for i in seq])\n",
    "y_train = np.array([i[-1] for i in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((191762, 5), (191762,), 40173)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пердставляем `y_train[i]` в виде вектора, в котором есть одна единица, которая соответсвует слову из вокабуляра, остальные все нули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(y_train, columns=[str(i) for i in range(1, vocab_size + 1)])\n",
    "\n",
    "new_dummies = {}\n",
    "for i in range(1, vocab_size + 1):\n",
    "    if i in dummies.columns:\n",
    "        new_dummies.update({i: dummies[i]})\n",
    "    else:\n",
    "        new_dummies.update({i: np.zeros(y_train.shape[0])})\n",
    "new_dummies = pd.DataFrame(new_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191762, 40173)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, задача преобразуется в задачу классификации, где по пяти словам надо предсказать одно слово из вокабуляра.\n",
    "\n",
    "Создаём сетку для решения этой задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15072/1169526264.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m model = Sequential([\n\u001b[0;32m      5\u001b[0m     \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_feature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautocast_variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayer_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\keras\\mixed_precision\\loss_scale_optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mloss_scale_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_delegate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\training\\experimental\\mixed_precision.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mloss_scale_optimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmixed_precision_global_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp2\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size + 1, 50, input_length=train_len),\n",
    "    LSTM(100, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использум `ModelCheckpoint`, чтобы сохранять прогресс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "filepath = \"./models/model_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем сетку на 100 эпохах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 8.6690 - accuracy: 0.0310\n",
      "Epoch 00001: loss improved from inf to 8.66899, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 157s 103ms/step - loss: 8.6690 - accuracy: 0.0310\n",
      "Epoch 2/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 8.2822 - accuracy: 0.0319\n",
      "Epoch 00002: loss improved from 8.66899 to 8.28243, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 158s 106ms/step - loss: 8.2824 - accuracy: 0.0319\n",
      "Epoch 3/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 7.9404 - accuracy: 0.0368\n",
      "Epoch 00003: loss improved from 8.28243 to 7.94039, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 160s 107ms/step - loss: 7.9404 - accuracy: 0.0368\n",
      "Epoch 4/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 7.6049 - accuracy: 0.0434\n",
      "Epoch 00004: loss improved from 7.94039 to 7.60499, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 157s 105ms/step - loss: 7.6050 - accuracy: 0.0434\n",
      "Epoch 5/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 7.2747 - accuracy: 0.0531\n",
      "Epoch 00005: loss improved from 7.60499 to 7.27460, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 102ms/step - loss: 7.2746 - accuracy: 0.0531\n",
      "Epoch 6/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 6.9360 - accuracy: 0.0674\n",
      "Epoch 00006: loss improved from 7.27460 to 6.93601, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 154s 103ms/step - loss: 6.9360 - accuracy: 0.0674\n",
      "Epoch 7/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 6.5830 - accuracy: 0.0859\n",
      "Epoch 00007: loss improved from 6.93601 to 6.58297, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 207s 138ms/step - loss: 6.5830 - accuracy: 0.0859\n",
      "Epoch 8/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 6.2262 - accuracy: 0.1049\n",
      "Epoch 00008: loss improved from 6.58297 to 6.22624, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 211s 141ms/step - loss: 6.2262 - accuracy: 0.1049\n",
      "Epoch 9/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 5.8829 - accuracy: 0.1245\n",
      "Epoch 00009: loss improved from 6.22624 to 5.88287, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 214s 143ms/step - loss: 5.8829 - accuracy: 0.1245\n",
      "Epoch 10/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 5.5483 - accuracy: 0.1434\n",
      "Epoch 00010: loss improved from 5.88287 to 5.54820, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 207s 138ms/step - loss: 5.5482 - accuracy: 0.1434\n",
      "Epoch 11/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 5.2233 - accuracy: 0.1629\n",
      "Epoch 00011: loss improved from 5.54820 to 5.22333, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 213s 142ms/step - loss: 5.2233 - accuracy: 0.1629\n",
      "Epoch 12/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 4.9079 - accuracy: 0.1841\n",
      "Epoch 00012: loss improved from 5.22333 to 4.90789, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 211s 141ms/step - loss: 4.9079 - accuracy: 0.1841\n",
      "Epoch 13/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 4.6067 - accuracy: 0.2078\n",
      "Epoch 00013: loss improved from 4.90789 to 4.60669, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 212s 141ms/step - loss: 4.6067 - accuracy: 0.2078\n",
      "Epoch 14/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 4.3185 - accuracy: 0.2342\n",
      "Epoch 00014: loss improved from 4.60669 to 4.31850, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 214s 143ms/step - loss: 4.3185 - accuracy: 0.2342\n",
      "Epoch 15/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 4.0494 - accuracy: 0.2637\n",
      "Epoch 00015: loss improved from 4.31850 to 4.04938, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 216s 144ms/step - loss: 4.0494 - accuracy: 0.2637\n",
      "Epoch 16/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 3.8087 - accuracy: 0.2954\n",
      "Epoch 00016: loss improved from 4.04938 to 3.80867, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 214s 143ms/step - loss: 3.8087 - accuracy: 0.2954\n",
      "Epoch 17/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 3.5870 - accuracy: 0.3253\n",
      "Epoch 00017: loss improved from 3.80867 to 3.58696, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 140ms/step - loss: 3.5870 - accuracy: 0.3253\n",
      "Epoch 18/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 3.3933 - accuracy: 0.3516\n",
      "Epoch 00018: loss improved from 3.58696 to 3.39331, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 216s 144ms/step - loss: 3.3933 - accuracy: 0.3516\n",
      "Epoch 19/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 3.2187 - accuracy: 0.3774\n",
      "Epoch 00019: loss improved from 3.39331 to 3.21869, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 208s 139ms/step - loss: 3.2187 - accuracy: 0.3774\n",
      "Epoch 20/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 3.0673 - accuracy: 0.3995\n",
      "Epoch 00020: loss improved from 3.21869 to 3.06730, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 215s 143ms/step - loss: 3.0673 - accuracy: 0.3995\n",
      "Epoch 21/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.9264 - accuracy: 0.4203\n",
      "Epoch 00021: loss improved from 3.06730 to 2.92640, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 139ms/step - loss: 2.9264 - accuracy: 0.4203\n",
      "Epoch 22/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.8029 - accuracy: 0.4392\n",
      "Epoch 00022: loss improved from 2.92640 to 2.80289, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 214s 143ms/step - loss: 2.8029 - accuracy: 0.4392\n",
      "Epoch 23/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.6902 - accuracy: 0.4581\n",
      "Epoch 00023: loss improved from 2.80289 to 2.69016, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 211s 140ms/step - loss: 2.6902 - accuracy: 0.4581\n",
      "Epoch 24/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.5859 - accuracy: 0.4739\n",
      "Epoch 00024: loss improved from 2.69016 to 2.58589, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 211s 141ms/step - loss: 2.5859 - accuracy: 0.4739\n",
      "Epoch 25/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.4887 - accuracy: 0.4897\n",
      "Epoch 00025: loss improved from 2.58589 to 2.48874, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 210s 140ms/step - loss: 2.4887 - accuracy: 0.4897\n",
      "Epoch 26/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.4082 - accuracy: 0.5018\n",
      "Epoch 00026: loss improved from 2.48874 to 2.40818, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 212s 142ms/step - loss: 2.4082 - accuracy: 0.5018\n",
      "Epoch 27/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.3202 - accuracy: 0.5162\n",
      "Epoch 00027: loss improved from 2.40818 to 2.32020, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 215s 143ms/step - loss: 2.3202 - accuracy: 0.5162\n",
      "Epoch 28/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.2513 - accuracy: 0.5273\n",
      "Epoch 00028: loss improved from 2.32020 to 2.25131, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 139ms/step - loss: 2.2513 - accuracy: 0.5273\n",
      "Epoch 29/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.1818 - accuracy: 0.5401\n",
      "Epoch 00029: loss improved from 2.25131 to 2.18184, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 210s 140ms/step - loss: 2.1818 - accuracy: 0.5401\n",
      "Epoch 30/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.1183 - accuracy: 0.5507\n",
      "Epoch 00030: loss improved from 2.18184 to 2.11831, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 208s 139ms/step - loss: 2.1183 - accuracy: 0.5507\n",
      "Epoch 31/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 2.0490 - accuracy: 0.5619\n",
      "Epoch 00031: loss improved from 2.11831 to 2.04904, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 214s 143ms/step - loss: 2.0490 - accuracy: 0.5619\n",
      "Epoch 32/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.9958 - accuracy: 0.5706\n",
      "Epoch 00032: loss improved from 2.04904 to 1.99585, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 139ms/step - loss: 1.9958 - accuracy: 0.5706\n",
      "Epoch 33/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.9474 - accuracy: 0.5800\n",
      "Epoch 00033: loss improved from 1.99585 to 1.94744, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 210s 140ms/step - loss: 1.9474 - accuracy: 0.5800\n",
      "Epoch 34/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.8995 - accuracy: 0.5887\n",
      "Epoch 00034: loss improved from 1.94744 to 1.89946, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 208s 139ms/step - loss: 1.8995 - accuracy: 0.5887\n",
      "Epoch 35/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.8487 - accuracy: 0.5965\n",
      "Epoch 00035: loss improved from 1.89946 to 1.84874, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 214s 142ms/step - loss: 1.8487 - accuracy: 0.5965\n",
      "Epoch 36/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.8048 - accuracy: 0.6063\n",
      "Epoch 00036: loss improved from 1.84874 to 1.80479, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 208s 139ms/step - loss: 1.8048 - accuracy: 0.6063\n",
      "Epoch 37/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.7612 - accuracy: 0.6120\n",
      "Epoch 00037: loss improved from 1.80479 to 1.76116, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 211s 140ms/step - loss: 1.7612 - accuracy: 0.6120\n",
      "Epoch 38/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.7242 - accuracy: 0.6196\n",
      "Epoch 00038: loss improved from 1.76116 to 1.72424, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 208s 139ms/step - loss: 1.7242 - accuracy: 0.6196\n",
      "Epoch 39/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.6837 - accuracy: 0.6272\n",
      "Epoch 00039: loss improved from 1.72424 to 1.68366, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 212s 141ms/step - loss: 1.6837 - accuracy: 0.6272\n",
      "Epoch 40/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.6485 - accuracy: 0.6337\n",
      "Epoch 00040: loss improved from 1.68366 to 1.64851, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 210s 140ms/step - loss: 1.6485 - accuracy: 0.6337\n",
      "Epoch 41/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.6134 - accuracy: 0.6401\n",
      "Epoch 00041: loss improved from 1.64851 to 1.61338, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 211s 141ms/step - loss: 1.6134 - accuracy: 0.6401\n",
      "Epoch 42/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.5796 - accuracy: 0.6460\n",
      "Epoch 00042: loss improved from 1.61338 to 1.57958, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 205s 137ms/step - loss: 1.5796 - accuracy: 0.6460\n",
      "Epoch 43/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.5475 - accuracy: 0.6519\n",
      "Epoch 00043: loss improved from 1.57958 to 1.54751, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 211s 141ms/step - loss: 1.5475 - accuracy: 0.6519\n",
      "Epoch 44/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.5184 - accuracy: 0.6571\n",
      "Epoch 00044: loss improved from 1.54751 to 1.51837, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 208s 139ms/step - loss: 1.5184 - accuracy: 0.6571\n",
      "Epoch 45/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.4928 - accuracy: 0.6633\n",
      "Epoch 00045: loss improved from 1.51837 to 1.49281, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 211s 141ms/step - loss: 1.4928 - accuracy: 0.6633\n",
      "Epoch 46/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.4632 - accuracy: 0.6676\n",
      "Epoch 00046: loss improved from 1.49281 to 1.46322, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 206s 137ms/step - loss: 1.4632 - accuracy: 0.6676\n",
      "Epoch 47/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.4345 - accuracy: 0.6722\n",
      "Epoch 00047: loss improved from 1.46322 to 1.43453, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 176s 117ms/step - loss: 1.4345 - accuracy: 0.6722\n",
      "Epoch 48/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.4041 - accuracy: 0.6794\n",
      "Epoch 00048: loss improved from 1.43453 to 1.40403, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 156s 104ms/step - loss: 1.4040 - accuracy: 0.6794\n",
      "Epoch 49/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.3854 - accuracy: 0.6815\n",
      "Epoch 00049: loss improved from 1.40403 to 1.38537, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.3854 - accuracy: 0.6815\n",
      "Epoch 50/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.3655 - accuracy: 0.6862\n",
      "Epoch 00050: loss improved from 1.38537 to 1.36556, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 153s 102ms/step - loss: 1.3656 - accuracy: 0.6862\n",
      "Epoch 51/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.3322 - accuracy: 0.6928\n",
      "Epoch 00051: loss improved from 1.36556 to 1.33229, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.3323 - accuracy: 0.6928\n",
      "Epoch 52/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.3185 - accuracy: 0.6947\n",
      "Epoch 00052: loss improved from 1.33229 to 1.31841, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.3184 - accuracy: 0.6947\n",
      "Epoch 53/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.2963 - accuracy: 0.6992\n",
      "Epoch 00053: loss improved from 1.31841 to 1.29625, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.2963 - accuracy: 0.6992\n",
      "Epoch 54/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.2742 - accuracy: 0.7038\n",
      "Epoch 00054: loss improved from 1.29625 to 1.27422, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.2742 - accuracy: 0.7038\n",
      "Epoch 55/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.2482 - accuracy: 0.7092\n",
      "Epoch 00055: loss improved from 1.27422 to 1.24825, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.2483 - accuracy: 0.7092\n",
      "Epoch 56/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.2469 - accuracy: 0.7094\n",
      "Epoch 00056: loss improved from 1.24825 to 1.24686, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 101ms/step - loss: 1.2469 - accuracy: 0.7094\n",
      "Epoch 57/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.2235 - accuracy: 0.7134\n",
      "Epoch 00057: loss improved from 1.24686 to 1.22362, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.2236 - accuracy: 0.7134\n",
      "Epoch 58/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.2039 - accuracy: 0.7178\n",
      "Epoch 00058: loss improved from 1.22362 to 1.20387, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 161s 107ms/step - loss: 1.2039 - accuracy: 0.7177\n",
      "Epoch 59/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.1850 - accuracy: 0.7214\n",
      "Epoch 00059: loss improved from 1.20387 to 1.18498, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.1850 - accuracy: 0.7214\n",
      "Epoch 60/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.1730 - accuracy: 0.7237\n",
      "Epoch 00060: loss improved from 1.18498 to 1.17307, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.1731 - accuracy: 0.7237\n",
      "Epoch 61/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.1599 - accuracy: 0.7258\n",
      "Epoch 00061: loss improved from 1.17307 to 1.15991, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 150s 100ms/step - loss: 1.1599 - accuracy: 0.7258\n",
      "Epoch 62/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.1434 - accuracy: 0.7296\n",
      "Epoch 00062: loss improved from 1.15991 to 1.14342, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.1434 - accuracy: 0.7296\n",
      "Epoch 63/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.1271 - accuracy: 0.7326\n",
      "Epoch 00063: loss improved from 1.14342 to 1.12710, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 1.1271 - accuracy: 0.7326\n",
      "Epoch 64/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.1121 - accuracy: 0.7354\n",
      "Epoch 00064: loss improved from 1.12710 to 1.11219, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 150s 100ms/step - loss: 1.1122 - accuracy: 0.7354\n",
      "Epoch 65/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.1011 - accuracy: 0.7379\n",
      "Epoch 00065: loss improved from 1.11219 to 1.10108, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 100ms/step - loss: 1.1011 - accuracy: 0.7379\n",
      "Epoch 66/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 1.0830 - accuracy: 0.7414\n",
      "Epoch 00066: loss improved from 1.10108 to 1.08306, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 162s 108ms/step - loss: 1.0831 - accuracy: 0.7414\n",
      "Epoch 67/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.7435\n",
      "Epoch 00067: loss improved from 1.08306 to 1.07470, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 208s 139ms/step - loss: 1.0747 - accuracy: 0.7435\n",
      "Epoch 68/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.0579 - accuracy: 0.7476\n",
      "Epoch 00068: loss improved from 1.07470 to 1.05791, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 140ms/step - loss: 1.0579 - accuracy: 0.7476\n",
      "Epoch 69/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.0459 - accuracy: 0.7496\n",
      "Epoch 00069: loss improved from 1.05791 to 1.04588, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 139ms/step - loss: 1.0459 - accuracy: 0.7496\n",
      "Epoch 70/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.0309 - accuracy: 0.7522\n",
      "Epoch 00070: loss improved from 1.04588 to 1.03092, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 139ms/step - loss: 1.0309 - accuracy: 0.7522\n",
      "Epoch 71/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.0204 - accuracy: 0.7553\n",
      "Epoch 00071: loss improved from 1.03092 to 1.02040, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 207s 138ms/step - loss: 1.0204 - accuracy: 0.7553\n",
      "Epoch 72/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.0112 - accuracy: 0.7574\n",
      "Epoch 00072: loss improved from 1.02040 to 1.01121, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 212s 142ms/step - loss: 1.0112 - accuracy: 0.7574\n",
      "Epoch 73/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 1.0019 - accuracy: 0.7581\n",
      "Epoch 00073: loss improved from 1.01121 to 1.00194, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 139ms/step - loss: 1.0019 - accuracy: 0.7581\n",
      "Epoch 74/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9865 - accuracy: 0.7621\n",
      "Epoch 00074: loss improved from 1.00194 to 0.98653, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 209s 140ms/step - loss: 0.9865 - accuracy: 0.7621\n",
      "Epoch 75/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9793 - accuracy: 0.7634\n",
      "Epoch 00075: loss improved from 0.98653 to 0.97926, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 153s 102ms/step - loss: 0.9793 - accuracy: 0.7634\n",
      "Epoch 76/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9667 - accuracy: 0.7656\n",
      "Epoch 00076: loss improved from 0.97926 to 0.96667, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 153s 102ms/step - loss: 0.9667 - accuracy: 0.7656\n",
      "Epoch 77/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9607 - accuracy: 0.7679\n",
      "Epoch 00077: loss improved from 0.96667 to 0.96072, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 154s 103ms/step - loss: 0.9607 - accuracy: 0.7679\n",
      "Epoch 78/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9522 - accuracy: 0.7684\n",
      "Epoch 00078: loss improved from 0.96072 to 0.95218, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 160s 107ms/step - loss: 0.9522 - accuracy: 0.7684\n",
      "Epoch 79/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9421 - accuracy: 0.7701\n",
      "Epoch 00079: loss improved from 0.95218 to 0.94207, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 154s 103ms/step - loss: 0.9421 - accuracy: 0.7701\n",
      "Epoch 80/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9316 - accuracy: 0.7732\n",
      "Epoch 00080: loss improved from 0.94207 to 0.93161, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 102ms/step - loss: 0.9316 - accuracy: 0.7732\n",
      "Epoch 81/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9228 - accuracy: 0.7749\n",
      "Epoch 00081: loss improved from 0.93161 to 0.92278, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 0.9228 - accuracy: 0.7749\n",
      "Epoch 82/100\n",
      "1499/1499 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.7779\n",
      "Epoch 00082: loss improved from 0.92278 to 0.90920, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 102ms/step - loss: 0.9092 - accuracy: 0.7779\n",
      "Epoch 83/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.9026 - accuracy: 0.7778\n",
      "Epoch 00083: loss improved from 0.90920 to 0.90258, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 154s 103ms/step - loss: 0.9026 - accuracy: 0.7777\n",
      "Epoch 84/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8957 - accuracy: 0.7810\n",
      "Epoch 00084: loss improved from 0.90258 to 0.89574, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 101ms/step - loss: 0.8957 - accuracy: 0.7810\n",
      "Epoch 85/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8887 - accuracy: 0.7815\n",
      "Epoch 00085: loss improved from 0.89574 to 0.88871, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 101ms/step - loss: 0.8887 - accuracy: 0.7815\n",
      "Epoch 86/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8782 - accuracy: 0.7834\n",
      "Epoch 00086: loss improved from 0.88871 to 0.87822, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 101ms/step - loss: 0.8782 - accuracy: 0.7834\n",
      "Epoch 87/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8700 - accuracy: 0.7851\n",
      "Epoch 00087: loss improved from 0.87822 to 0.86998, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 101ms/step - loss: 0.8700 - accuracy: 0.7851\n",
      "Epoch 88/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8676 - accuracy: 0.7857\n",
      "Epoch 00088: loss improved from 0.86998 to 0.86759, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 0.8676 - accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8554 - accuracy: 0.7895\n",
      "Epoch 00089: loss improved from 0.86759 to 0.85540, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 0.8554 - accuracy: 0.7895\n",
      "Epoch 90/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8499 - accuracy: 0.7904\n",
      "Epoch 00090: loss improved from 0.85540 to 0.84986, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 0.8499 - accuracy: 0.7904\n",
      "Epoch 91/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8378 - accuracy: 0.7921\n",
      "Epoch 00091: loss improved from 0.84986 to 0.83777, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 102ms/step - loss: 0.8378 - accuracy: 0.7921\n",
      "Epoch 92/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8309 - accuracy: 0.7945\n",
      "Epoch 00092: loss improved from 0.83777 to 0.83093, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 152s 101ms/step - loss: 0.8309 - accuracy: 0.7945\n",
      "Epoch 93/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8266 - accuracy: 0.7952\n",
      "Epoch 00093: loss improved from 0.83093 to 0.82665, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 0.8266 - accuracy: 0.7952\n",
      "Epoch 94/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8104 - accuracy: 0.7991\n",
      "Epoch 00094: loss improved from 0.82665 to 0.81042, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 151s 101ms/step - loss: 0.8104 - accuracy: 0.7991\n",
      "Epoch 95/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8155 - accuracy: 0.7981\n",
      "Epoch 00095: loss did not improve from 0.81042\n",
      "1499/1499 [==============================] - 162s 108ms/step - loss: 0.8155 - accuracy: 0.7981\n",
      "Epoch 96/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8148 - accuracy: 0.7964\n",
      "Epoch 00096: loss did not improve from 0.81042\n",
      "1499/1499 [==============================] - 161s 107ms/step - loss: 0.8148 - accuracy: 0.7965\n",
      "Epoch 97/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.8062 - accuracy: 0.7999\n",
      "Epoch 00097: loss improved from 0.81042 to 0.80623, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 161s 108ms/step - loss: 0.8062 - accuracy: 0.7998\n",
      "Epoch 98/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.7959 - accuracy: 0.8009\n",
      "Epoch 00098: loss improved from 0.80623 to 0.79596, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 160s 106ms/step - loss: 0.7960 - accuracy: 0.8009\n",
      "Epoch 99/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.7888 - accuracy: 0.8034\n",
      "Epoch 00099: loss improved from 0.79596 to 0.78884, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 159s 106ms/step - loss: 0.7888 - accuracy: 0.8034\n",
      "Epoch 100/100\n",
      "1498/1499 [============================>.] - ETA: 0s - loss: 0.7824 - accuracy: 0.8046\n",
      "Epoch 00100: loss improved from 0.78884 to 0.78240, saving model to ./models\\model_weights.hdf5\n",
      "1499/1499 [==============================] - 159s 106ms/step - loss: 0.7824 - accuracy: 0.8046\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, new_dummies, epochs=100,\n",
    "                    batch_size=128, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На предикшене задаём начало анекдота, берём на каждой итерации последние 5 слов и пытаемся предсказать следующее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate(model, seq, max_len=20):\n",
    "    tokenized_sent = tokenizer.texts_to_sequences([seq])\n",
    "    max_len = max_len + len(tokenized_sent[0])\n",
    "\n",
    "    while len(tokenized_sent[0]) < max_len:\n",
    "        padded_sentence = pad_sequences(tokenized_sent[-5:], maxlen=5)\n",
    "        op = model.predict(np.asarray(padded_sentence).reshape(1,-1))\n",
    "        tokenized_sent[0].append(op.argmax() + 1)\n",
    "\n",
    "    return seq + ' ' + \" \".join(map(lambda x : reverse_word_map[x],tokenized_sent[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пара примеров работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ехали в поезде в поезде коллегами сотрудников отменить его отдых из местных малого части к ситуации к том что в самоизоляции кричал робинзон крузо во'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, 'Ехали в поезде')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Приятель из Питера Сергей Дединский приятель из питера сергей одиночные выходные при масках маникюр на нашей конституции просто подвергнут появился эксперты к царе менеджеров году телевизор© люди что российская'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, 'Приятель из Питера Сергей Дединский')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось не особо смешно конечно. Думаю, основная причина - это то, что из-за того что не получилось разобраться, как обойти ограничение по памяти, обучающая выборка оказалась слишком маленькой, и сетка не смогла нормально натренироваться, чтобы предсказывать что-то адекватное. Возможно, ещё стоило поэксперементировать с разными архитектурами, и поподбирать оптимальное количество слов, по которым предсказывается следующее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f5a2599355624a556240fdc3f0627c4e0016588722ee170139ef0bcc4cc5fb5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
