{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('./data/train.parquet')\n",
    "test_df = pd.read_parquet('./data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df.target\n",
    "train_data = train_df[['Title', 'Body']]\n",
    "test_data = test_df[['Title', 'Body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка тегов\n",
    "Каждый пост содержит несколько тегов. Преобразуем стоки тегов в столбцы, в каждом из которых будет один тег (аля One Hot Enconding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tags(text):\n",
    "    return text[1: -1].split('><')\n",
    "\n",
    "tags = pd.concat([train_df['Tags'], test_df['Tags']])\n",
    "tags = tags.apply(lambda x: split_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = []\n",
    "for _, value in tags.items():\n",
    "    unique_tags += value\n",
    "unique_tags, tags_counts = np.unique(unique_tags, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего уникальных тегов: 10703\n"
     ]
    }
   ],
   "source": [
    "print(f'Всего уникальных тегов: {len(unique_tags)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь отсортируем все теги почастоте встречаемости и оставим 1000 самых популярных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idxs = np.argsort(tags_counts)[::-1]\n",
    "tags_counts = tags_counts[sorted_idxs]\n",
    "unique_tags = unique_tags[sorted_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(2000), tags_counts[:2000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tags = 1000\n",
    "n_train, n_test = train_data.shape[0], test_data.shape[0]\n",
    "top_tags = unique_tags[:n_tags]\n",
    "tags_features = np.zeros((n_train + n_test, n_tags), dtype=np.int8)\n",
    "\n",
    "for i, (_, tags_list) in enumerate(tags.items()):\n",
    "    for j, tag in enumerate(top_tags):\n",
    "        if tag in tags_list:\n",
    "            tags_features[i: j] = 1\n",
    "\n",
    "tags_train = tags_features[:n_train]\n",
    "tags_test = tags_features[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_train_csr = sparse.csr_matrix(tags_features[:n_train])\n",
    "tags_test_csr = sparse.csr_matrix(tags_features[n_train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "Распределение классов равномерое, так что никаких дополнительных действий по баласировке не требуется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, x_train_tags, x_val_tags, y_train, y_val = train_test_split(train_data, tags_train, labels, test_size=.1, stratify=labels, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def apply_bow(train_data, test_data):\n",
    "    bow = CountVectorizer()\n",
    "    train_bow = bow.fit_transform(train_data)\n",
    "    test_bow= bow.transform(test_data)\n",
    "    return train_bow, test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_title_bow, x_val_title_bow = apply_bow(x_train.Title, x_val.Title)\n",
    "x_train_body_bow, x_val_body_bow = apply_bow(x_train.Body, x_val.Body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow = sparse.hstack([x_train_title_bow, x_train_body_bow, x_train_tags])\n",
    "x_val_bow = sparse.hstack([x_val_title_bow, x_val_body_bow, x_val_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def apply_tfidf(train_data, test_data):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    train_tfidf = tfidf.fit_transform(train_data)\n",
    "    test_tfidf = tfidf.transform(test_data)\n",
    "    return train_tfidf, test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_title_tfidf, x_val_title_tfidf = apply_tfidf(x_train.Title, x_val.Title)\n",
    "x_train_body_tfidf, x_val_body_tfidf = apply_tfidf(x_train.Body, x_val.Body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf = sparse.hstack([x_train_title_tfidf, x_train_body_tfidf, x_train_tags])\n",
    "x_val_tfidf = sparse.hstack([x_val_title_tfidf, x_val_body_tfidf, x_val_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import downloader\n",
    "w2v_model = downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(sentence, model):\n",
    "    vecs = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            vecs.append(w2v_model.get_vector(word.lower()))\n",
    "        except:\n",
    "            pass\n",
    "    if len(vecs) == 0:\n",
    "        vecs = [np.zeros(300)]\n",
    "    return sum(vecs) / len(vecs)\n",
    "\n",
    "def apply_word2vec(data):\n",
    "    title = np.array([sentence2vec(sentence, w2v_model) for sentence in data['Title']])\n",
    "    body = np.array([sentence2vec(sentence, w2v_model) for sentence in data['Body']])\n",
    "    return np.hstack([title, body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_w2v = np.hstack([apply_word2vec(x_train), x_train_tags])\n",
    "x_val_w2v = np.hstack([apply_word2vec(x_val), x_val_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glove_model = downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_glove(data):\n",
    "    title = np.array([sentence2vec(sentence, glove_model) for sentence in data['Title']])\n",
    "    body = np.array([sentence2vec(sentence, glove_model) for sentence in data['Body']])\n",
    "    return np.hstack([title, body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_glove = np.hstack([apply_glove(x_train), x_train_tags])\n",
    "x_val_glove = np.hstack([apply_glove(x_val), x_val_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим инфраструктуру для валидации моделей и подбора лучших параметров. Из алгоритмов будем использовать логистическую регрссию и ансамбль kNN + Random Forest + LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "def get_log_reg(trial=None, C=1):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    if trial is not None:\n",
    "        C = trial.suggest_loguniform('C', 1e-5, 1e+3)\n",
    "\n",
    "    return LogisticRegression(C=C, max_iter=10000, random_state=0)\n",
    "\n",
    "def get_stacking(trial=None,\n",
    "                 n_neighbors=5,\n",
    "                 n_estimators=100, min_samples_split=2, min_samples_leaf=1,\n",
    "                 C=1):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    if trial is not None:\n",
    "        n_neighbors = trial.suggest_int('n_neighbors', 5, 100)\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "        C = trial.suggest_loguniform('C', 1e-5, 1e+3)\n",
    "\n",
    "    estimators = [\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=n_neighbors)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=n_estimators, min_samples_split=min_samples_split,\n",
    "                                      min_samples_leaf=min_samples_leaf, random_state=0))\n",
    "    ]\n",
    "    final = LogisticRegression(C=C, max_iter=10000, random_state=0)\n",
    "\n",
    "    return StackingClassifier(estimators=estimators, final_estimator=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective_function(estimator_func, train_data, train_labels, test_data, test_labels=None, trial=None):\n",
    "    estimator = estimator_func(trial=trial).fit(train_data, train_labels)\n",
    "    if test_labels is not None:\n",
    "        prediction = estimator.predict(test_data)\n",
    "        return accuracy_score(test_labels, prediction)\n",
    "    else:\n",
    "        return estimator.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(estimator_func, train_data, train_labels, test_data, test_labels, n_trials=10):\n",
    "    study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n",
    "                                direction='maximize',\n",
    "                                pruner=optuna.pruners.HyperbandPruner())\n",
    "    objective = lambda trial: objective_function(estimator_func, train_data, train_labels, test_data, test_labels, trial)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = [\n",
    "    (x_train_bow, x_val_bow),\n",
    "    (x_train_tfidf, x_val_tfidf),\n",
    "    (x_train_w2v, x_val_w2v),\n",
    "    (x_train_glove, x_val_glove),\n",
    "]\n",
    "validation_names = ['bow', 'tfidf', 'word2vec', 'glove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:35:27,457]\u001b[0m A new study created in memory with name: no-name-997cf3ed-39af-4a0b-9ac5-b71bbc3203fa\u001b[0m\n",
      "C:\\Users\\nikti\\miniconda3\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n",
      " 10%|█         | 1/10 [03:21<30:11, 201.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:38:48,708]\u001b[0m Trial 0 finished with value: 0.8039583333333333 and parameters: {'C': 3.730383528143731}. Best is trial 0 with value: 0.8039583333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [03:38<12:22, 92.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:39:05,685]\u001b[0m Trial 1 finished with value: 0.8185416666666666 and parameters: {'C': 0.0019458738403480128}. Best is trial 1 with value: 0.8185416666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:51<06:36, 56.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:39:19,245]\u001b[0m Trial 2 finished with value: 0.7895833333333333 and parameters: {'C': 0.0006528473243309113}. Best is trial 1 with value: 0.8185416666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [05:25<07:07, 71.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:40:52,759]\u001b[0m Trial 3 finished with value: 0.823125 and parameters: {'C': 0.25734643279726915}. Best is trial 3 with value: 0.823125.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [08:40<09:40, 116.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:44:08,453]\u001b[0m Trial 4 finished with value: 0.8029166666666666 and parameters: {'C': 5.698384608345687}. Best is trial 3 with value: 0.823125.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [09:22<06:02, 90.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:44:49,705]\u001b[0m Trial 5 finished with value: 0.8325 and parameters: {'C': 0.024257815076676004}. Best is trial 5 with value: 0.8325.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [15:22<08:56, 178.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:50:50,134]\u001b[0m Trial 6 finished with value: 0.7895833333333333 and parameters: {'C': 701.6387837751602}. Best is trial 5 with value: 0.8325.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [18:01<05:44, 172.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:53:28,970]\u001b[0m Trial 7 finished with value: 0.80375 and parameters: {'C': 3.0104949891579693}. Best is trial 5 with value: 0.8325.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [19:02<02:17, 137.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:54:29,595]\u001b[0m Trial 8 finished with value: 0.8295833333333333 and parameters: {'C': 0.0703809641382708}. Best is trial 5 with value: 0.8325.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [19:35<00:00, 117.57s/it]\n",
      "\u001b[32m[I 2021-12-04 13:55:03,170]\u001b[0m A new study created in memory with name: no-name-15acf5cb-3848-46ba-a335-f531edf3917b\u001b[0m\n",
      "C:\\Users\\nikti\\miniconda3\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:55:03,165]\u001b[0m Trial 9 finished with value: 0.8354166666666667 and parameters: {'C': 0.013706928443177698}. Best is trial 9 with value: 0.8354166666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:09<19:29, 129.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:57:13,161]\u001b[0m Trial 0 finished with value: 0.8189583333333333 and parameters: {'C': 3.730383528143731}. Best is trial 0 with value: 0.8189583333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:14<07:27, 55.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:57:17,187]\u001b[0m Trial 1 finished with value: 0.7108333333333333 and parameters: {'C': 0.0019458738403480128}. Best is trial 0 with value: 0.8189583333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [02:17<03:44, 32.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:57:20,889]\u001b[0m Trial 2 finished with value: 0.6908333333333333 and parameters: {'C': 0.0006528473243309113}. Best is trial 0 with value: 0.8189583333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:55<03:25, 34.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 13:57:58,327]\u001b[0m Trial 3 finished with value: 0.8177083333333334 and parameters: {'C': 0.25734643279726915}. Best is trial 0 with value: 0.8189583333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [05:07<05:47, 69.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:00:10,389]\u001b[0m Trial 4 finished with value: 0.816875 and parameters: {'C': 5.698384608345687}. Best is trial 0 with value: 0.8189583333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [05:22<03:24, 51.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:00:25,725]\u001b[0m Trial 5 finished with value: 0.7758333333333334 and parameters: {'C': 0.024257815076676004}. Best is trial 0 with value: 0.8189583333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [11:24<07:37, 152.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:06:27,394]\u001b[0m Trial 6 finished with value: 0.793125 and parameters: {'C': 701.6387837751602}. Best is trial 0 with value: 0.8189583333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [13:01<04:30, 135.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:08:04,806]\u001b[0m Trial 7 finished with value: 0.8197916666666667 and parameters: {'C': 3.0104949891579693}. Best is trial 7 with value: 0.8197916666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [13:25<01:40, 100.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:08:28,679]\u001b[0m Trial 8 finished with value: 0.798125 and parameters: {'C': 0.0703809641382708}. Best is trial 7 with value: 0.8197916666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:35<00:00, 81.58s/it]\n",
      "\u001b[32m[I 2021-12-04 14:08:38,987]\u001b[0m A new study created in memory with name: no-name-5b5b40bc-5fb6-444f-8054-12ca7dfede70\u001b[0m\n",
      "C:\\Users\\nikti\\miniconda3\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:08:38,982]\u001b[0m Trial 9 finished with value: 0.7608333333333334 and parameters: {'C': 0.013706928443177698}. Best is trial 7 with value: 0.8197916666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:18<11:43, 78.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:09:57,183]\u001b[0m Trial 0 finished with value: 0.630625 and parameters: {'C': 3.730383528143731}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:24<04:47, 35.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:10:03,497]\u001b[0m Trial 1 finished with value: 0.5475 and parameters: {'C': 0.0019458738403480128}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:27<02:26, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:10:06,578]\u001b[0m Trial 2 finished with value: 0.5289583333333333 and parameters: {'C': 0.0006528473243309113}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:07<02:50, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:10:46,322]\u001b[0m Trial 3 finished with value: 0.6285416666666667 and parameters: {'C': 0.25734643279726915}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [03:41<04:20, 52.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:12:20,416]\u001b[0m Trial 4 finished with value: 0.63 and parameters: {'C': 5.698384608345687}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [03:58<02:40, 40.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:12:37,350]\u001b[0m Trial 5 finished with value: 0.5995833333333334 and parameters: {'C': 0.024257815076676004}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [05:43<03:04, 61.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:14:22,895]\u001b[0m Trial 6 finished with value: 0.6308333333333334 and parameters: {'C': 701.6387837751602}. Best is trial 6 with value: 0.6308333333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [07:06<02:16, 68.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:15:45,878]\u001b[0m Trial 7 finished with value: 0.6308333333333334 and parameters: {'C': 3.0104949891579693}. Best is trial 6 with value: 0.6308333333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [07:32<00:54, 54.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:16:11,447]\u001b[0m Trial 8 finished with value: 0.6114583333333333 and parameters: {'C': 0.0703809641382708}. Best is trial 6 with value: 0.6308333333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [07:46<00:00, 46.63s/it]\n",
      "\u001b[32m[I 2021-12-04 14:16:25,317]\u001b[0m A new study created in memory with name: no-name-a08e4380-cbd3-494e-a552-35a2cbde7c14\u001b[0m\n",
      "C:\\Users\\nikti\\miniconda3\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:16:25,312]\u001b[0m Trial 9 finished with value: 0.58375 and parameters: {'C': 0.013706928443177698}. Best is trial 6 with value: 0.6308333333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:15<11:16, 75.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:17:40,488]\u001b[0m Trial 0 finished with value: 0.630625 and parameters: {'C': 3.730383528143731}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:21<04:35, 34.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:17:46,450]\u001b[0m Trial 1 finished with value: 0.5475 and parameters: {'C': 0.0019458738403480128}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:24<02:20, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:17:49,420]\u001b[0m Trial 2 finished with value: 0.5289583333333333 and parameters: {'C': 0.0006528473243309113}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:01<02:41, 26.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:18:26,966]\u001b[0m Trial 3 finished with value: 0.6285416666666667 and parameters: {'C': 0.25734643279726915}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [03:29<04:05, 49.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:19:55,272]\u001b[0m Trial 4 finished with value: 0.63 and parameters: {'C': 5.698384608345687}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [03:45<02:31, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:20:11,218]\u001b[0m Trial 5 finished with value: 0.5995833333333334 and parameters: {'C': 0.024257815076676004}. Best is trial 0 with value: 0.630625.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [05:27<02:56, 58.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:21:53,197]\u001b[0m Trial 6 finished with value: 0.6308333333333334 and parameters: {'C': 701.6387837751602}. Best is trial 6 with value: 0.6308333333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [06:49<02:12, 66.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:23:14,858]\u001b[0m Trial 7 finished with value: 0.6308333333333334 and parameters: {'C': 3.0104949891579693}. Best is trial 6 with value: 0.6308333333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [07:14<00:53, 53.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:23:39,896]\u001b[0m Trial 8 finished with value: 0.6114583333333333 and parameters: {'C': 0.0703809641382708}. Best is trial 6 with value: 0.6308333333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [07:28<00:00, 44.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-04 14:23:53,616]\u001b[0m Trial 9 finished with value: 0.58375 and parameters: {'C': 0.013706928443177698}. Best is trial 6 with value: 0.6308333333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg_studies = []\n",
    "for x_train, x_val in validation_data:\n",
    "    study = optimize(get_log_reg, x_train, y_train, x_val, y_val)\n",
    "    log_reg_studies.append(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores:\n",
      "\tbow:\t0.8354166666666667\n",
      "\ttfidf:\t0.8197916666666667\n",
      "\tword2vec:\t0.6308333333333334\n",
      "\tglove:\t0.6308333333333334\n"
     ]
    }
   ],
   "source": [
    "print('Best scores:')\n",
    "for study, name in zip(log_reg_studies, validation_names):\n",
    "    print(f'\\t{name}:\\t{study.best_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "Запустил только на одну попытку из-за того, что тренировка занимает очень много времени. В целом, точность там примерно такая же, как и на логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-05 16:47:44,953]\u001b[0m A new study created in memory with name: no-name-6f3f8772-ce02-48ec-a205-a210d9e18710\u001b[0m\n",
      "C:\\Users\\nikti\\miniconda3\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n",
      "100%|██████████| 1/1 [12:32<00:00, 752.76s/it]\n",
      "\u001b[32m[I 2021-12-05 17:00:17,721]\u001b[0m A new study created in memory with name: no-name-8dc416f4-435f-4dd0-bd8a-617be060750e\u001b[0m\n",
      "C:\\Users\\nikti\\miniconda3\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-05 17:00:17,713]\u001b[0m Trial 0 finished with value: 0.7879166666666667 and parameters: {'n_neighbors': 71, 'n_estimators': 179, 'min_samples_split': 4, 'min_samples_leaf': 6, 'C': 5.698384608345687}. Best is trial 0 with value: 0.7879166666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [11:36<00:00, 696.84s/it]\n",
      "\u001b[32m[I 2021-12-05 17:11:54,568]\u001b[0m A new study created in memory with name: no-name-094c27f1-b6e9-42ca-a14a-4f603bd7254c\u001b[0m\n",
      "C:\\Users\\nikti\\miniconda3\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-05 17:11:54,559]\u001b[0m Trial 0 finished with value: 0.8045833333333333 and parameters: {'n_neighbors': 71, 'n_estimators': 179, 'min_samples_split': 4, 'min_samples_leaf': 6, 'C': 5.698384608345687}. Best is trial 0 with value: 0.8045833333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [12:48<00:00, 768.30s/it]\n",
      "\u001b[32m[I 2021-12-05 17:24:42,870]\u001b[0m A new study created in memory with name: no-name-9a6d132d-a3a4-4df1-948a-acd9713a32fe\u001b[0m\n",
      "C:\\Users\\nikti\\miniconda3\\envs\\nlp\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-05 17:24:42,864]\u001b[0m Trial 0 finished with value: 0.5997916666666666 and parameters: {'n_neighbors': 71, 'n_estimators': 179, 'min_samples_split': 4, 'min_samples_leaf': 6, 'C': 5.698384608345687}. Best is trial 0 with value: 0.5997916666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [10:33<00:00, 633.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-05 17:35:16,708]\u001b[0m Trial 0 finished with value: 0.5997916666666666 and parameters: {'n_neighbors': 71, 'n_estimators': 179, 'min_samples_split': 4, 'min_samples_leaf': 6, 'C': 5.698384608345687}. Best is trial 0 with value: 0.5997916666666666.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stacking_studies = []\n",
    "for x_train, x_val in validation_data:\n",
    "    study = optimize(get_stacking, x_train, y_train, x_val, y_val, n_trials=1)\n",
    "    stacking_studies.append(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores:\n",
      "\tbow:\t0.7879166666666667\n",
      "\ttfidf:\t0.8045833333333333\n",
      "\tword2vec:\t0.5997916666666666\n",
      "\tglove:\t0.5997916666666666\n"
     ]
    }
   ],
   "source": [
    "print('Best scores:')\n",
    "for study, name in zip(stacking_studies, validation_names):\n",
    "    print(f'\\t{name}:\\t{study.best_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим кастомный датасет для наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackOverflowDataset(Dataset):\n",
    "    def __init__(self, filename) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.read_parquet(filename)\n",
    "\n",
    "        self.title = self.data['Title']\n",
    "        self.body = self.data['Body']\n",
    "        self.tags = self.data['Tags']\n",
    "        self.target = self.data['target'] if 'target' in self.data.columns else None\n",
    "\n",
    "        def split_tags(text):\n",
    "            return ' '.join(text[1: -1].split('><'))\n",
    "        self.tags = self.tags.apply(lambda x: split_tags(x))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.title.iloc[idx] + self.body.iloc[idx] + self.tags.iloc[idx]\n",
    "        if self.target is not None:\n",
    "            return data, self.target.iloc[idx]\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = StackOverflowDataset('./data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_text, _label) in batch:\n",
    "         label_list.append(_label)\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter = StackOverflowDataset('./data/train.parquet')\n",
    "dataloader = DataLoader(train_iter, batch_size=32, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственно сама нейронка со слоем эмбеддингов и двумя fully-connected слоями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        linear_output = self.fc(embedded)\n",
    "        return self.fc2(linear_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = StackOverflowDataset('./data/train.parquet')\n",
    "num_class = len(set([label for (_, label) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 128\n",
    "hidden_dim = 32\n",
    "model = TextClassificationModel(vocab_size, emsize, hidden_dim, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, optimizer, epoch, criterion):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, text, offsets in dataloader:\n",
    "            predicted_label = model(text, offsets)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "train_iter = StackOverflowDataset('./data/train.parquet')\n",
    "test_iter = StackOverflowDataset('./data/test.parquet')\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/  713 batches | accuracy    0.683\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 24.61s | valid accuracy    0.806 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/  713 batches | accuracy    0.811\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 24.14s | valid accuracy    0.833 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/  713 batches | accuracy    0.847\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 24.39s | valid accuracy    0.820 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/  713 batches | accuracy    0.892\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 25.23s | valid accuracy    0.872 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/  713 batches | accuracy    0.893\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 27.86s | valid accuracy    0.873 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/  713 batches | accuracy    0.896\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 27.43s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/  713 batches | accuracy    0.899\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 25.97s | valid accuracy    0.873 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/  713 batches | accuracy    0.901\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 29.01s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/  713 batches | accuracy    0.902\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 27.68s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/  713 batches | accuracy    0.904\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 25.65s | valid accuracy    0.876 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader, optimizer, epoch, criterion)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch, time.time() - epoch_start_time, accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "Ожидаемо, алгоритмы классического машинного обучения показали себя хуже Deep Learning.\n",
    "\n",
    "Из препроцессинга лучше всего себя показал BOW, близко к нему TF-IDF. А вот предобученные модели, Word2Vec и Glove, не дали прироста к точности"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f5a2599355624a556240fdc3f0627c4e0016588722ee170139ef0bcc4cc5fb5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
